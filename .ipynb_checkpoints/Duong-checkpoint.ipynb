{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# import data\n",
    "train_set= pd.read_csv('./Data/train.csv', index_col= 'id')\n",
    "test_set= pd.read_csv('./Data/test.csv', index_col= 'id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all duplicated columns\n",
    "duplicated_cols_dict= {}\n",
    "duplicated_cols_list_full = []\n",
    "\n",
    "for i, col in enumerate(train_set.columns):\n",
    "    duplicated_cols_list= []\n",
    "    # if the col is already one of the keys\n",
    "    # then skip\n",
    "    if col in duplicated_cols_list_full:\n",
    "        continue\n",
    "    for c in train_set.columns:\n",
    "        if (train_set[col].equals(train_set[c])):\n",
    "            duplicated_cols_list.append(c)\n",
    "            duplicated_cols_list_full.append(c)\n",
    "        \n",
    "           \n",
    "    if (len(duplicated_cols_list) > 1):\n",
    "        duplicated_cols_dict[col] = duplicated_cols_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cbook import flatten\n",
    "\n",
    "drop_cols = set(list(flatten(list(duplicated_cols_dict.values())))) - set(duplicated_cols_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set= train_set.drop(drop_cols, axis= 1)\n",
    "test_set= test_set.drop(drop_cols, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_Vincent = train_set.columns[:97]\n",
    "cols_Duong = train_set.columns[97:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_counts= train_set.isna().sum()\n",
    "fig, ax = plt.subplots(figsize= (20,15))\n",
    "total_samples= len(train_set)\n",
    "\n",
    "ax.bar(na_counts.index,na_counts.values/total_samples)\n",
    "ax.set_xlabel(\"column \", fontsize= 30)\n",
    "ax.set_ylabel(\"counts\", fontsize= 30)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_title(\"Percentages of missing values in each column\", fontsize= 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Labels count\")\n",
    "train_set.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = train_set.corr()['label'].sort_values()\n",
    "# exclude nan corrs\n",
    "corrs = corrs[corrs.values < 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (20,15))\n",
    "total_samples= len(train_set)\n",
    "\n",
    "ax.bar(corrs.index,corrs.values)\n",
    "ax.set_xlabel(\"column \", fontsize= 30)\n",
    "ax.set_ylabel(\"correlation\", fontsize= 30)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_title(\"Correlation with labels\", fontsize= 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duong's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Duong = train_set[cols_Duong]\n",
    "data_Duong['label']= train_set['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Duong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_counts= data_Duong.isna().sum().sort_values()\n",
    "fig, ax = plt.subplots(figsize= (20,15))\n",
    "total_samples= len(data_Duong)\n",
    "\n",
    "ax.bar(na_counts.index,na_counts.values/total_samples)\n",
    "ax.set_xlabel(\"column \", fontsize= 30)\n",
    "ax.set_ylabel(\"counts\", fontsize= 30)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_title(\"Percentages of missing values in each column\", fontsize= 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = data_Duong.corr()['label'].sort_values()\n",
    "# exclude nan corrs\n",
    "corrs = corrs[corrs.values < 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (20,15))\n",
    "total_samples= len(data_Duong)\n",
    "\n",
    "ax.bar(corrs.index, corrs.values)\n",
    "ax.set_xlabel(\"column \", fontsize= 30)\n",
    "ax.set_ylabel(\"correlation\", fontsize= 30)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_title(\"Correlation with labels\", fontsize= 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[['Field_46', 'Field_48', 'Field_49']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data_Duong['label'],\\\n",
    "            data_Duong['homeTownCountry'], dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(data_Duong.columns):\n",
    "    print (i+1, \"/ Column name:\", col)\n",
    "    print(data_Duong[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create custom columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column diff_start_end_date = diff between E_startDate and E_endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Duong.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data_Duong['E_endDate'] = data_Duong['E_endDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))\n",
    "\n",
    "data_Duong['E_startDate'] = data_Duong['E_startDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "data_Duong['F_endDate'] = data_Duong['F_endDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))\n",
    "\n",
    "data_Duong['F_startDate'] = data_Duong['F_startDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))\n",
    "\n",
    "data_Duong['G_startDate'] = data_Duong['G_startDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))\n",
    "\n",
    "data_Duong['G_endDate'] = data_Duong['G_endDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))               \n",
    "\n",
    "\n",
    "data_Duong['A_endDate'] = data_Duong['A_endDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))\n",
    "\n",
    "data_Duong['A_startDate'] = data_Duong['A_startDate'].apply(lambda row: \\\n",
    "              datetime.strptime('1900-01-01', '%Y-%m-%d') \\\n",
    "                    if row is np.nan \\\n",
    "                else datetime.strptime(row, '%Y-%m-%d'))               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *letter*_diff_date = diff between *letter*_startDate and *letter*_endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Duong['E_diff_date']= data_Duong['E_endDate'] - data_Duong['E_startDate']\n",
    "\n",
    "data_Duong['F_diff_date']= data_Duong['F_endDate'] - data_Duong['F_startDate']\n",
    "\n",
    "data_Duong['G_diff_date']= data_Duong['G_endDate'] - data_Duong['G_startDate']\n",
    "\n",
    "data_Duong['A_diff_date']= data_Duong['A_endDate'] - data_Duong['A_startDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore topfriends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFriends_counts = data_Duong['topFriends'].value_counts(dropna= False)\n",
    "plt.bar(topFriends_counts.index, topFriends_counts.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFriends_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['E_endDate'].equals(train_set['G_endDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[['Field_14','Field_16']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if (i%3 == 0):\n",
    "        continue\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cbook import flatten\n",
    "\n",
    "set(list(flatten(list(duplicated_cols_dict.values())))) - set(duplicated_cols_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = set(list(flatten(list(duplicated_cols_dict.values())))) - set(duplicated_cols_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_cols_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = set(list(flatten(list(duplicated_cols_dict.values())))) - set(duplicated_cols_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(duplicated_cols_dict.values()) - set(duplicated_cols_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all duplicated columns\n",
    "duplicated_cols_dict= {}\n",
    "duplicated_cols_list_full = []\n",
    "\n",
    "for i, col in enumerate(train_set.columns):\n",
    "    duplicated_cols_list= []\n",
    "    # if the col is already one of the keys\n",
    "    # then skip\n",
    "    if col in duplicated_cols_list_full:\n",
    "        continue\n",
    "    for c in train_set.columns:\n",
    "        if (train_set[col].equals(train_set[c])):\n",
    "            duplicated_cols_list.append(c)\n",
    "            duplicated_cols_list_full.append(c)\n",
    "        \n",
    "           \n",
    "    if (len(duplicated_cols_list) > 1):\n",
    "        duplicated_cols_dict[col] = duplicated_cols_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
