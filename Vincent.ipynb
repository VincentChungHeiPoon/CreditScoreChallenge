{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Score challenge with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from datetime import datetime\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boy19\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (35,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\boy19\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (34,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(r'Data/train.csv')\n",
    "test_set = pd.read_csv(r'Data/test.csv')\n",
    "\n",
    "cols_Vincent = train_set.columns[:97]\n",
    "cols_Duong = train_set.columns[97:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# store all duplicated columns\n",
    "duplicated_cols_dict= {}\n",
    "duplicated_cols_list_full = []\n",
    "\n",
    "\n",
    "# THIS FUNCTION is to drop all duplicates columns\n",
    "for i, col in enumerate(train_set.columns):\n",
    "    duplicated_cols_list= []\n",
    "    # if the col is already one of the keys\n",
    "    # then skip\n",
    "    if col in duplicated_cols_list_full:\n",
    "        continue\n",
    "    for c in train_set.columns:\n",
    "        if (train_set[col].equals(train_set[c])):\n",
    "            duplicated_cols_list.append(c)\n",
    "            duplicated_cols_list_full.append(c)\n",
    "                   \n",
    "    if (len(duplicated_cols_list) > 1):\n",
    "        duplicated_cols_dict[col] = duplicated_cols_list   \n",
    "    \n",
    "drop_cols = set(list(flatten(list(duplicated_cols_dict.values())))) - set(duplicated_cols_dict.keys())\n",
    "train_set = train_set.drop(drop_cols, axis= 1)\n",
    "test_set  = test_set.drop(drop_cols, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[train_set.columns[:74]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.drop(columns = ['id','Field_1', 'Field_2', 'Field_5', 'Field_6', 'Field_7', 'Field_8', 'Field_9', 'Field_11',\n",
    "                         'Field_15', 'Field_18', 'Field_25', 'Field_32', 'Field_33', 'Field_34', 'Field_35', 'ngaySinh', 'diaChi', 'Field_40',\n",
    "                         'Field_43', 'Field_44', 'Field_45', 'Field_46', 'Field_48', 'Field_49', 'Field_56', 'Field_61', 'Field_68', \n",
    "                          'maCv'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Field_3</th>\n",
       "      <th>Field_4</th>\n",
       "      <th>Field_10</th>\n",
       "      <th>Field_12</th>\n",
       "      <th>Field_13</th>\n",
       "      <th>Field_19</th>\n",
       "      <th>Field_20</th>\n",
       "      <th>Field_21</th>\n",
       "      <th>Field_22</th>\n",
       "      <th>...</th>\n",
       "      <th>Field_67</th>\n",
       "      <th>Field_69</th>\n",
       "      <th>Field_70</th>\n",
       "      <th>Field_71</th>\n",
       "      <th>Field_72</th>\n",
       "      <th>Field_73</th>\n",
       "      <th>Field_74</th>\n",
       "      <th>Field_75</th>\n",
       "      <th>Field_76</th>\n",
       "      <th>Field_77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4258600.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118410.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>T1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1073365.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  Field_3 Field_4  Field_10 Field_12  Field_13  Field_19   Field_20  \\\n",
       "0      1      1.0      GH       1.0       G8       1.0       0.0  4258600.0   \n",
       "1      0      NaN     NaN       NaN      NaN       NaN       NaN        NaN   \n",
       "2      0      2.0      T1       1.0      NaN       1.0       0.0  5000000.0   \n",
       "3      0      NaN     NaN       NaN      NaN       NaN       NaN        NaN   \n",
       "4      1      NaN     NaN       NaN      NaN       NaN       NaN        NaN   \n",
       "\n",
       "   Field_21  Field_22  ...   Field_67  Field_69  Field_70  Field_71  Field_72  \\\n",
       "0       4.5       1.0  ...   118410.0      0.00      0.49     0.245      0.49   \n",
       "1       NaN       NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
       "2       4.5       1.0  ...  1073365.0      0.58      0.77     0.675      0.19   \n",
       "3       NaN       NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
       "4       NaN       NaN  ...        NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "  Field_73 Field_74 Field_75  Field_76  Field_77  \n",
       "0      NaN      NaN      5.0       0.0       2.0  \n",
       "1      1.0    704.0      6.0       2.0       2.0  \n",
       "2      1.0   1076.0      2.0       0.0       2.0  \n",
       "3      NaN      NaN      NaN       NaN       NaN  \n",
       "4      NaN      NaN      NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    0.538687\n",
       "1.0    0.461313\n",
       "Name: Field_3, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_Field3 = train_set.Field_3.value_counts()/train_set.Field_3.value_counts().sum()\n",
    "info_Field3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "field3_random = random.choice(info_Field3.index, size= len(train_set), p = info_Field3.values)\n",
    "train_set['Field_3'] = np.where(train_set['Field_3'].isnull(),\\\n",
    "            field3_random,\\\n",
    "            train_set['Field_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fill_Cat_Var(df, col_name, seed_val = 76):\n",
    "    random.seed(seed_val)\n",
    "    for name in col_name:\n",
    "        info = df[name].value_counts()/df[name].value_counts().sum()\n",
    "        random_val = random.choice(info.index, size= len(df), p = info.values)\n",
    "        df[name] = np.where(df[name].isnull(), random_val, df[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fill_Cat_Var(train_set, ['Field_3', 'Field_4', 'Field_10', 'Field_12', 'Field_13', 'Field_19', 'Field_20', 'Field_21', 'Field_22',\n",
    "                        'Field_23', 'Field_27', 'Field_28', 'Field_29', 'namSinh', 'gioiTinh', 'Field_36', 'Field_38', \n",
    "                         'Field_39', 'Field_41', 'Field_42', 'Field_47', 'Field_50', 'Field_51', 'Field_53', 'Field_54',\n",
    "                        'Field_55', 'Field_58', 'Field_59', 'Field_60', 'Field_62', 'Field_63','Field_64', 'Field_65','Field_66', \n",
    "                        'Field_67', 'Field_69', 'Field_70', 'Field_71', 'Field_72', 'Field_73', 'Field_74', 'Field_75', \n",
    "                         'Field_76', 'Field_77'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'Field_3', 'Field_4', 'Field_10', 'Field_12', 'Field_13',\n",
       "       'Field_19', 'Field_20', 'Field_21', 'Field_22', 'Field_23', 'Field_27',\n",
       "       'Field_28', 'Field_29', 'namSinh', 'gioiTinh', 'Field_36', 'Field_38',\n",
       "       'Field_39', 'Field_41', 'Field_42', 'Field_47', 'Field_50', 'Field_51',\n",
       "       'Field_53', 'Field_54', 'Field_55', 'Field_58', 'Field_59', 'Field_60',\n",
       "       'Field_62', 'Field_63', 'Field_64', 'Field_65', 'Field_66', 'Field_67',\n",
       "       'Field_69', 'Field_70', 'Field_71', 'Field_72', 'Field_73', 'Field_74',\n",
       "       'Field_75', 'Field_76', 'Field_77'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('Duong_Dumbass.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
